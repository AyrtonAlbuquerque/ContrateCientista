\chapter{Referencial te\'orico}\label{cap:referencialTeorico}

\section{Inteligência Artifical}\label{sec:ia}

Os conceitos modernos de \gls{ia} surgiram na década de 1950, com as idéias propostas por Alan Turing e a noção de uma "máquina pensante". Turing propôs um teste, ao qual chamou de "O Jogo da Imitação" e que hoje é mais conhecido como o teste de Turing, cujo objetivo é determinar se uma máquina pode ser classificada como inteligente. \cite{Turing1950}.

Inteligência Artifical pode ser subdividida em quatro categorias principais, sistemas que pensam como humanos, sistemas que agem como humanos, sistemas que pensam racionalmente e sistemas que agem racionalmente \cite{RussellIA2021}.

\subsection{Sistemas que Pensam como Humanos}\label{subsec:ia1}

Sistemas que pensam como humanos tentam simular os processos mentais e cognitivos humanos, como pensamento, aprendizado e tomada de decisão. Um dos primeiros esforços nessa direção foi a criação de modelos baseados em redes neurais artificiais. Inspiradas na estrutura biológica do cérebro, as redes neurais foram propostas originalmente por McCulloch e Pitts \cite{McCulloch1943}, que introduziram o conceito de "neurônio artificial". Posteriormente, os avanços nesse campo, como o Perceptron de Rosenblatt \cite{Rosenblatt1958}, marcaram o início das tentativas de replicar a capacidade de aprendizado humano por meio de sistemas computacionais.

\subsection{Sistemas que Agem como Humanos}\label{subsec:ia2}

Sistemas que agem como humanos simulam o comportamento observável, como em tarefas de conversação ou reconhecimento de padrões. Os chatbots são um exemplo claro dessa abordagem, pois tentam interagir de maneira natural com usuários. Estes sistemas geralmente se utilizam de métodos de processamento de linguagem natural para interpretar e responder perguntas de um usuário humano, que muitas vezes ser incapaz de distinguir se seu interlocutor é humano ou máquina, aproximando-se do objetivo do teste de Turing.

\subsection{Sistemas que Pensam Racionalmente}\label{subsec:ia3}

Sistemas que pensam racionalmente baseiam-se na lógica formal, utilizando-se de regras e inferências lógicas na tomada de decisões. Uma aplicação clássica desse paradigma foi o Logic Theorist, criado por Allen Newell e Herbert Simon em 1956 \cite{NewellSimon1976}. Este sistema foi projetado para provar teoremas em lógica proposicional e é considerado um dos primeiros programas de inteligência artificial. Outro exemplo é o Prolog (Programming in Logic) \cite{Colmerauer1973}, uma linguagem de programação declarativa amplamente usada em aplicações de \gls{ia} baseadas em raciocínio lógico, como sistemas especialistas e planejamento automatizado.

\subsection{Sistemas que Agem Racionalmente}\label{subsec:ia4}

Sistemas que agem racionalmente tomam decisões de forma a maximizar a realização de um objetivo específico, Esses sistemas seguem o paradigma do \textit{"agente racional"}, agindo de forma a alcançar os melhores resultados esperados, considerando o conhecimento disponível e as incertezas do ambiente. Esse conceito é amplamente utilizado em áreas automatização, robótica e jogos. \cite{Poole2010}. Diferentemente dos sistemas que pensam racionalmente, um agente racional é mais flexível e são utilizados em aplicações mais dinâmicas, como por exemplo dirigir carros autônomos.

\section{Aprendizado de Máquina}\label{subsec:ml}

O \gls{ml} é uma subárea da \gls{ia} cujo objetivo é aprimorar o desempenho de um sistema através da experiência, sem que seja necessário uma programação direta. De acordo com Mitchell (1997), \textit{"um programa de aprendizado é dito aprender de uma experiência E com relação a uma tarefa T e uma medida de desempenho P, se seu desempenho em T, medido por P, melhora com E".} \cite{Mitchell1997}. 

Os principais tipos de aprendizado de máquina são o aprendizado supervisionado, o aprendizado não supervisionado e o aprendizado por reforço. 

\subsection{Aprendizado Supervisionado}\label{subsec:ml1}

No aprendizado supervisionado, o modelo é treinado com um conjunto de dados anotados ou rotulados, onde uma entrada já é associada a uma saída corretamente classificada. O objetivo é que o modelo aprenda a mapear as entradas para as saídas corretas e possa então generalizar para novas entradas não vistas anteriormente. \cite{Goodfellow2016}.

A qualidade e a quantidade dos dados são cruciais no aprendizado supervisionado, pois dados rotulados de forma inadequada ou insuficientes podem levar a modelos com baixo desempenho ou incapazes de realizar generalizações.

\subsection{Aprendizado não Supervisionado}\label{subsec:ml2}

No aprendizado não supervisionado, os dados não são rotulados e o modelo é construído de maneira a encontrar padrões e/ou agrupamentos nos dados. Este tipo de treinamento é muito utilizado em áreas como processamento de linguagem natural, onde os algoritimos são treinados de forma a aprender representações semânticas de palavras. \cite{Goodfellow2016}.

Uma das principais vantagens do aprendizado não supervisionado é a capacidade de se trabalhar com grandes volumes de dados sem a necessidade de rotulação prévia, o que acaba por reduzir os esforços manuais para o treinamento de modelos. \cite{Murphy2012}.  

\subsection{Aprendizado por Reforço}\label{subsec:ml3}

No aprendizado por reforço, o modelo é treinado de forma dinâmica, sendo recompensado ou penalizado de acordo com suas decisões. Sutton e Barto definem essa abordagem como uma técnica na qual o aprendizado ocorre sem supervisão direta, apenas a partir do feedback fornecido pelo ambiente, baseado nas ações executadas pelo agente. \cite{SuttonBarto2018}.

Um dos benefícios fundamentais desse método é sua capacidade de otimizar estratégias de longo prazo, mesmo em ambientes altamente dinâmicos e incertos. O agente deve equilibrar a busca por novas ações e a exploração das ações que já demonstraram ser eficazes. O aprendizado por reforço pode demandar alta capacidade computacional, especialmente em ambientes complexos e com alta dimensionalidade. \cite{SuttonBarto2018}

\section{Processamento de Linguagem Natural}\label{subsec:nlp}

\gls{nlp} é a subárea da \gls{ia} cujo objetivo é construir sistemas computacionais capazes de interpretar e reproduzir a linguagem humana, seja ela escrita ou falada, abrangendo tarefas como processamento de texto, compreensão de estrutura sintática e análise semântica. \cite{JurafskyMartin2023}.

\subsection{Tokenização}\label{subsec:nlp1}

Um dos conceitos mais básicos do processamento de linguagem natural é o de tokenização, sendo este um dos passos iniciais responsável por dividir um texto em unidades menores denominadas tokens, como palavras, frases ou caracteres. O intuito da tokenização é facilitar a análise e o processamento de um texto, permitindo que estes sejam convertidos em uma representação adequada para modelos computacionais. Jurafsky e Martin explicam que a tokenização é um pré-requisito essencial para diversas tarefas de \gls{nlp}, como análise semântica, tradução automática e treinamento de modelos linguísticos, pois facilita o mapeamento de dados textuais para representações numéricas que possam ser utilizadas em aprendizado de máquina. \cite{JurafskyMartin2023}.

\subsection{Análise Sintática}\label{subsec:nlp2}

A análise sintática, também conhecida como parsing, é o processo de análise da estrutura gramatical de uma sentença, e em processamento de linguagem natural representa o passo anterior à análise semântica. Essa análise identifica como as palavras se relacionam sintática e hierarquicamente umas com as outras, construindo uma representação estruturada, geralmente na forma de árvore ou grafo, visando compreender como os elementos de uma sentença se organizam de acordo com as regras gramaticais de uma língua. Jurafsky e Martin definem a análise sintática como a tarefa de determinar a estrutura sintática de uma sentença de acordo com uma gramática formal e livres de contexto. \cite{JurafskyMartin2023}.

\subsection{Análise Semântica}\label{subsec:nlp3}

Segmentar um texto em tokens não é suficiente para uma análise complexa, é necessário também interpretar o significado das palavras e sentenças, isso quer dizer que é necessário analisar o texto semânticamente, ou seja, buscar entender as relações e os conceitos por trás das palavras e o contexto nas quais estão inseridas.

A análise semântica pode ser vista como um processo de modelagem que mapeia palavras para significados e os organiza de maneira relacional, considerando tanto informações lexicais quanto contextuais. \cite{JurafskyMartin2023}. É tarefa da análise semântica lidar com problemas como a ambiguidade, relações entre entidades em uma sentença e fenômenos linguísticos como metáforas e ironias. Este tipo de análise permite que modelos modernos possam realizar tarefas complexas como análise de sentimento e extração de informações relevantes de um conjunto de dados de grande volume.

\section{Representação Distribuída e Representação Contextual}\label{subsec:embeddings_transformers}

Em processamento de linguagem natural, duas das formas mais comuns de representação de significado são as representações distribuídas, também conhecidas como embeddings, e representações contextuais. 

\subsection{Representação Distribuída (Embeddings)}\label{subsec:embeddings}

O conceito de representações distribuídas baseia-se na hipótese distribucional, proposta por Harris et al. (1954), onde palavras que ocorrem em contextos similares tendem a ter significados semelhantes. Isso levou ao desenvolvimento de modelos que aprendem representações semânticas com base nos contextos em que as palavras aparecem. \cite{Harris1954}.

Representações distribuídas transformam palavras em vetores numéricos estáticos baseados em seus contextos e nos dados de treinamento, permitindo capturar relações semânticas e sintáticas, como sinônimos e analogias, a partir da distância vetorial entre elas. Embbedings possuem uma complexidade computacional baixa, o que os torna mais eficientes para tarefas simples, como classificação e agrupamentos, porém sua eficiência é limitida para conjunto de dados maiores, pois as relações semânticas em frases ou textos longos podem não ser bem modelados.

\subsection{Representação Contextual (Transformers)}\label{subsec:transformers}

Transformadores ou transformers são representações contextuais e correspondem a uma evolução das representações distribuídas, incorporando o contexto dinâmico das palavras em um texto, não mais atribuindo uma representação vetorial estática para cada palavra. 

Um dos conceitos mais importantes para os transformers é o mecanismo de atenção, descrito por Vaswani et al. (2017), como \textit{"um mapeamento de uma consulta e um conjunto de pares chave-valor para uma saída, onde a consulta, chaves, valores e saída são todos vetores. A saída é computada como a soma dos pesos dos valores, onde o peso associado a cada valor é computado por uma função de compatibilidade da consulta com a chave correspondente"}. \cite{VaswaniTransformer2017}. A partir deste mecanismo o modelo avalia a relevância de cada palavra em relação às outras dentro de uma sequência, atribuindo pesos para cada interação.

Transformers introduzem uma complexidade computacional maior, porém, são capazes de modelar uma entrada de dados mais complexa com melhor precisão e escalabilidade. Esta forma de representação se popularizou com o surgimento de modelos baseados em transformadores, como o \gls{bert} e o \gls{gpt}.

\section{Grandes Modelos de Linguagem}\label{sec:llm}

Os grandes modelos de linguagem são sistemas de aprendizado de máquina treinados com um grande volume de dados com o objetivo de desempenharem tarefas de processamento de linguagem natural com alta precisão. Estes modelos são baseados principalmente em arquiteturas de transformadores, revolucionando o campo do processamento de linguagem natural por sua capacidade de lidar com uma vasta gama de tarefas como geração de textos, sumarização, tradução automática, geração de códigos e análise de sentimentos. \cite{IBMLLM}.

O diferencial dos grandes modelos de linguagem está em seu tamanho, medido pelo número de parâmetros treináveis, que podem variar de milhões a centenas de bilhões ou mais. O treinamento de modelos dessa magnitute possui um custo elevado, requerindo uma infraestrutura computacional robusta, gigantescos volumes de dados e um tempo elevado de treinamento. 

O treinamento dos \gls{llm} é baseado nos paradigmas de pré-treinamento (pre-training) e ajustes finos (fine-tuning). No pré-treinamento, o modelo aprende a prever o próximo token em uma sequência usando uma abordagem auto-supervisionada. Posteriormente, ele pode ser ajustado para tarefas específicas através do fine-tuning, que adapta os parâmetros do modelo a domínios especializados. \cite{Zhou2023}.

\section{REST}\label{sec:rest}

\gls{rest} é um paradigma arquitetural que define como recursos de uma aplicação devem ser representados e permite a integração e comunicação entre sistemas distribuídos através do uso do protocolo \gls{http}. Estes recursos representam objetos ou dados identificados por \gls{uri}, que podem ser acessados e manipulados por meio de métodos \gls{http}. \cite{Fielding2000}.

Uma das mais importantes caracteristicas da arquitetura \gls{rest} é a ausência de dependências contextuais entre requisições consecutivas, também conhecida como stateless. Essa característica habilita uma implementação mais simplificada, com melhor escalabilidade e desacoplamento entre os sistemas. Além disso, o uso de representações padronizadas, como \gls{json} ou \gls{xml}, permite que diferentes sistemas troquem informações de forma eficiente independente de linguagem de implementação.

\subsection{Protocolo HTTP}\label{subsec:http}

O \gls{http} é um protocolo a nível de aplicação para comunicação entre sistemas distrubuídos e é um dos pilares da comunicação web moderna, definindo regras e padrões para a requisição e obtenção de recursos entre aplicações cliente e servidores na internet. Criado no início da década de 1990 pelo CERN e mais tarde padronizado pelo consórcio World Wide Web (W3C) e pela Internet Engineering Task Force (IETF), o HTTP evoluiu significativamente desde sua primeira versão, HTTP/0.9, até a atual, HTTP/3. \cite{Fielding1999}.

O \gls{http} é um protocolo sem estado (stateless), o que significa que cada requisição do cliente para o servidor é tratada de forma independente, sem memória de requisições anteriores. O protocolo utiliza mensagens de requisição e resposta. As mensagens de requisição incluem um método ou verbo \gls{http}, um \gls{uri} de recurso, e informações adicionais nos cabeçalhos. As respostas retornam um código de status que indicam o resultado da operação, e os dados do recurso solicitado no corpo da mensagem.

Os quatro métodos ou verbos mais comuns do \gls{http} são GET, POST, PUT e DELETE e representam operações básicas que podem ser efetuadas sobre um recurso. O método GET é utilizado na recuperação de um recurso, sem a alteração de seu estado e idempotente, ou seja, sucessivas chamadas deste método produzem o mesmo resultado. O método POST é utilizado para a criação de um recurso e não idempotente. O método PUT é utilizado para a atualização de um recurso e por fim o método DELETE é utilizado para a remoção de um recurso, sendo estes também idempotentes.